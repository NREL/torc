.. _jobs:

####
Jobs
####

Input Parameters
================
Users can define these parameters in the workflow specification file or through CLI/API input
commands:

- **command**: String invoked by torc to run a job. It is typically an executable with a unique set
  of arguments and options. The executable can look up other input parameters from the database.
  Refer to :ref:`job_input_output_data` for a discussion of of how to store input and output data
  for jobs.
- **cancel_on_blocking_job_failure**: If this is set to true and a job upon which this job is
  dependent fails, torc will cancel this job.
- **scheduler**: This optional parameter can be set for two conditions. First, if a job is
  initially blocked, you can set this with the name of a scheduler that you want torc to
  automatically schedule for you. You must set ``needs_compute_node_schedule`` as well. Secondly,
  you may have one scheduler configuration for big-memory jobs and another for small-memory jobs.
  This will prevent the big-memory nodes from taking small-memory jobs.
- **needs_compute_node_schedule**: As mentioned above with ``scheduler``, setting this to ``true``
  can enable automatic compute node scheduling.
- **supports_termination**: Should be set to true if the job handles the signal ``SIGTERM``. Refer
  to :ref:`job_graceful_shutdown`.

Torc Parameters
===============
- **key**: Unique identifier of the job in the database. By default, generated by the database.
  Users can define their own keys, but this is not recommended in most situations.
- **status**: Current status of the job in a workflow. Refer to :ref:`job_status`.
- **run_id**: Integer representing one job execution. Starts at one and increases every time the
  workflow is restarted.

.. _job_resource_requirements:

Resource Requirements
=====================
You can store definitions of job resource requirements in the database and then associate them with
jobs. This is critical because it informs torc about what jobs can be run in parallel on a single
compute node.

The recommended way of defining these relationships is through the workflow specification (JSON5)
file. One set of resource requirements looks like this:

.. code-block:: JavaScript

    {
      name: "large",
      num_cpus: 36,
      num_gpus: 0,
      num_nodes: 1,
      memory: "80g",
      runtime: "P0DT12H"
    }

This says that any job assigned these requirements will consume 36 CPUs, 80 GB of memory, and run
for 12 hours.

You assign one or more jobs to these requirements in the ``resource_requirements`` field of the job
specification: ``resource_requirements: "large"``.

.. _job_input_output_data:

Job Input/Output Data
=====================

Torc provides a mechanism for users to store input and output data in the database. This data can
be stored on a per-job basis or for the overall workflow. Torc uses the ``user_data`` collection
for this.

You can store job-to-job relationships if one job stores data that will be consumed by one or more
other jobs. This is analagous to job-file-job relationships discussed elsewhere. In both cases torc
will sequence execution of jobs based on these dependencies.

One way to run jobs with different parameters is to pass those parameters as command-line arguments
and options. A second way is to store the input parameters in the ``user_data`` collection of the
database. A common runner script can pull the parameters for each specific job at runtime.

.. note:: Torc sets the environment variables TORC_WORKFLOW_KEY and TORC_JOB_KEY. Scripts can
   use these values to retrieve data from the database.

Jobs can also store result data and metatdata in the database.

.. warning:: The database is not currently designed to store large result data. You can store
   small result data or pointers to where the actual data resides.

Here is how to store and retrieve user data from torc CLI commands. Refer to
:ref:`passing_data_between_jobs` for an example using the workflow specification file and API
commands.

Torc CLI
--------

Add data to the database.

.. code-block:: console

   $ torc user-data add -n my_val -s 92181820 -d "{key1: 'val1', key2: 'val2'}"
   2023-03-29 09:45:59,678 - INFO [torc.cli.user_data user_data.py:41] : Added user_data key=92398595

.. code-block:: console

   $ torc jobs list-user-data 92181820
   [
     {
       "_key": "92340362",
       "_rev": "_fw4IkZ----",
       "key3": "val3"
     },
     {
       "_key": "92340378",
       "_rev": "_fw4IkX----",
       "key1": "val1",
       "key2": "val2"
     }
   ]


.. code-block:: console

   $ torc user-data list
   [
     {
       "_key": "92398595",
       "_rev": "_fw4IkX----",
       "key1": "val1",
       "key2": "val2"
     },
   ]

   $ torc user-data get 92398595
   {
     '_key': '92398595',
     '_rev': '_fw2IcgK---',
     'key1': 'val1',
     'key2': 'val2'
   }

   $ torc user-data delete 92398595 92398602
   2023-03-29 09:47:56,772 - INFO [torc.cli.user_data user_data.py:54] : Deleted user_data=92398595
   2023-03-29 09:47:56,799 - INFO [torc.cli.user_data user_data.py:54] : Deleted user_data=92398602

Add a placeholder item to the database. The actual data will be populated in the database by job
92340392 and then consumed by job 92340393. Torc will ensure that 92340393 cannot run until
92340392 completes.

.. code-block:: console

   $ torc user-data add --name output_data1 --stores 92340392 --consumes 92340393

Ephemeral data
--------------
The ``user_data`` collection offers an optional field to control ephemeral data. This is useful for
cases where you want to ensure that a job always runs in workflow restarts because it creates a
resource needed by other jobs. Torc will clear the ``data`` field of all ``user_data`` documents if
the ``is_ephemeral`` flag is true (it defaults to false).

One example of how this can be used is an Apache Spark cluster needed by a job. Let's suppose that
the cluster does not exist beforehand and needs to be created by the workflow. One way to
accomplish this is to add a job that creates the cluster, create a ``user_data`` document as a
placeholder for the cluster URL, declare that the cluster-create script will store the data, and
declare that the work job will consume the data. Torc will sequence the jobs just that the
cluster-create script runs first, it uploads the URL, then, when the work script runs, it reads the
URL and connects to the cluster.

.. _job_graceful_shutdown:

Graceful shutdown of jobs
=========================
A common error condition in HPC environments is underestimating the walltime for a job. The HPC
scheduler will kill the job. If you don't take precautions, you will lose the work and have to
start from the beginning.

Similar to Slurm, Torc offers one procedure to help with this problem: the
``supports_termination`` flag in the job defintion. If this is set to true then torc will send the
signal ``SIGTERM`` to each job process. If your job registers a signal handler for that signal, you
can gracefully shutdown such that a subsequent process can resume where it left off.

Don't set this flag if your job doesn't catch SIGTERM. Torc will attempt to wait for the process
exit and capture its return code.

Torc performs these actions two minutes before the walltime timeout. That value can be customized
by setting the ``compute_node_worker_buffer_seconds`` field in the ``config`` section of a workflow
specification file.

Refer to this script for a Python example of detecting this signal:
https://github.nrel.gov/viz/wms/blob/main/torc/tests/scripts/sleep.py

.. note:: The torc worker application on compute nodes handles SIGTERM. If you configure Slurm to
   terminate jobs at earlier time than the torc two-minute buffer, torc will respect it.
